本项目主要实现了使用 `xgboost` 和 `cnn` 算法实现恶意流量的分类, 使用数据集 `CIC-IDS 2017`, 其中 `xgboost` 还像模像样的, `cnn` 的效果奇差, 前端的同学在做的时候不小心把模型切换的功能阉割掉了, 在比赛提交的时候我也没有发现, 现在已经彻底放弃了. 

本项目作为本人进入大学以来开发维护的第一个项目, 代码风格幼稚, 技术含量没有, 文件结构混乱, bug 一大堆, 以此纪念我青涩二愚蠢的大二时光和在三教喂蚊子的夜.

本项目最终 __耻获__ `上海市应用能力大赛三等奖`, 本代码的最终可执行文件不可执行, 因为 `xgboost` 打包的时候的 dll 链接问题实在是无力解决了, __燃尽了__. 如果有后来者希望参加这个比赛, __劝退劝退劝退__! 写代码真的好累, 含金量几乎没有. 

- __鸣谢__:
  1. 感谢我的队友 `BoWen La` 和 `XuYang Liu`, 我坑死他们了. 
  2. 感谢我的指导老师 `YingXiao Xu` 和 `XiangDong Zhang`, 作为复旦大学的优秀教师, 一世英名都毁在这个项目上了.

本 _README.md_ 主要改编自 __设计说明书__.(好吧, 其实一个字没动)

# 简介

## 作品创意/项目背景

随着网络技术的飞速发展，计算机网络环境变得日益复杂，恶意流量对网络安全构成了严重威胁。从频繁出现的网络攻击事件到数据泄露事故，恶意流量的危害无处不在。我们的作品创意正是源于对当前网络安全形势的深刻洞察，旨在为各类网络环境提供一套高效、智能的恶意流量监测解决方案。​

本平台的主要功能包括实时监测网络流量、精准识别恶意流量类型、及时发出预警信息以及对历史流量数据进行分析统计。通过这些功能，成果的应用目标是帮助企业、机构及个人有效防范网络攻击，保障网络系统的稳定运行，降低因恶意流量导致的经济损失和数据风险。​

## 项目实施计划

在人员分工方面，团队成员三人分别负责算法设计，前端开发和环境搭建，算法设计的同学负责选择合适的机器学习和深度学习的方法，通过数据结构对网络数据包进行特征提取和模型训练，从而实现精准的恶意流量识别。前端开发的同学负责完成恶意流量平台数据可视化以及一些配置环节的可视化。环境搭建的同学负责搭建远程服务器并配置网络抓包环境，从而对平台进行全面测试，查找并修复潜在问题，同时保障平台在运行过程中的稳定性。最后，由三人根据在项目中的贡献共同完成项目相关文档，包括说明书和用户手册等。

在设计制作进度安排上，项目前期进行需求调研与分析，通过阅读论文，咨询老师等方式了解深度学习相关技术和恶意流量检测的常见方法，确定平台的功能需求和技术选型，为期 2 周。随后进入算法设计与开发阶段，耗时 4 周，重点研发适用于恶意流量监测的深度学习模型。接着在系统开发阶段，用 6 周时间搭建平台架构，实现各个功能模块。完成开发后，进行 3 周的全面测试与优化，修复发现的问题，提升平台性能。最后 1 周进行项目收尾工作，整理文档，准备项目交付。

# 总体设计

## 系统功能

### 功能概述

系统实现的主要功能包括流量采集、流量分析、恶意流量识别、预警通知以及数据管理。系统性能方面，具备高准确性，能够在复杂网络环境下精准识别恶意流量，误报率控制在极低水平；拥有高实时性，能够快速响应网络流量变化，及时发现并处理恶意流量；具备良好的扩展性，可根据实际需求灵活调整监测范围和深度。

图1系统功能框架图

### 功能说明

**恶意流量实时检测**：通过scapy的asnysniff函数对端口的出入的数据包进行监听，支持多种常见采集协议，确保数据完整准确。系统运用深度学习算法对采集到的数据进行实时预处理，包括清洗、特征提取等操作，通过分析流量大小、连接数、协议类型等特征，实时识别 DDoS 攻击、SQL 注入攻击、恶意软件传播等常见恶意流量类型。在可视化界面的实时监测界面显示模型识别出来的攻击流量占比和攻击类型。

**历史数据分析**：支持查看过去7分钟，7小时或7天的恶意流量与正常流量占比，以及恶意流量的攻击类型。

**pcap 文件分析**：允许用户通过输入pcap路径，系统自动对其进行解析与分析。通过清洗、特征提取等步骤处理文件内的流量数据，进而识别其中是否存在恶意流量，并以本地保存恶意流量结果，包括恶意流量类型、占比等信息，方便用户深入了解特定网络数据包的安全状况。

**参数配置**：用户可在系统中灵活配置各项关键参数。如设置数据包特征提取间隔，选择不同的深度学习算法等，确保系统能够根据实际网络环境与安全需求进行个性化定制，高效稳定运行。

## 系统软硬件平台

### 系统开发平台（含开源/第三方工具）

1\. 模型训练：window11家庭版，使用pycharm professional 24.0.1版本

2\. 软件开发：wsl 24.12.0和utunbu 24.04.1LTS平台，使用vscode平台开发

3\. 测试环境：阿里云平台

### 系统运行平台系统运行的硬件和软件环境：

源代码运行条件：需 Python 版本在 3.10 及以上。运行所依赖的库有用于深度学习框架的 PyTorch、实现梯度提升算法的 XGBoost、机器学习常用工具集 Scikit - learn、图像处理库 OpenCV2、网络数据包处理库 Scapy，以及用于构建快速 API 的 FastAPI 。

打包软件操作：在 Linux 系统环境下，用户能够以超级用户权限（sudo）直接运行打包软 件，操作简便快捷。

系统架构模式：系统采用集中式架构，这种架构使得所有核心业务逻辑以及数据处理工作集 中于单一中心节点，有助于提升管理效率，保障系统运行的稳定性。

部署软件需求：无

## 关键技术

**（一）Pcap 文件的特征提取**

恶意流量在部分统计特征方面，与正常流量存在显著差异。本项目运用 xgboost 机器学习算法，对带有不同标签的流量特征展开学习，在一定程度上实现了多分类的恶意流量分类。在处理 pcap 文件的特征提取时，采用了 CIC - IDS - 2017 数据集。该数据集收集了 5 天内的正常与恶意流量，以 Pcap 文件形式存储，大小共计 48.8G，并配套提供了 csv 文件。csv 文件依据流的五元组（目的 ip、源 ip、目的端口、源端口、协议），对不同的流进行了标记。然而，如何高效地将大尺寸的 pcap 文件按会话级别进行分割，成为一大挑战。

在本项目设计中，精心构建了 FlowKey、SessionKey、FlowPackage、SessionPackage 类，借助哈希函数和字典来识别并存储不同的流和数据。鉴于此类大文件若一次性读入网络包并完成标签匹配，在时间和空间上均不可行，故而采用 scapy 库中 rdpcap 函数的逐包读取功能。同时，维护一个优先队列，用于记录 pcap 文件中每个流的过期时间，以便及时对过期数据包进行数据写入操作，并释放内存。此外，利用多线程并行处理多个 pcap 文件，最终在本次实验环境下，成功在 20 分钟内完成了 pcap 文件的分割。

**（二）流特征的提取**

传统基于机器学习的恶意流量特征提取方法，通常仅关注流的特征，而忽视了整个会话的特征，这显然存在局限性。在本次项目的流量特征提取过程中，针对流同时提取会话层面与流层面的特征。并且，考虑到在实时恶意流量特征提取场景下，对恶意流量特征的判断不能在流结束后才进行，而传统数据集特征常常忽略这一点。因此，本次恶意流量特征提取设置 packet_batch_size 为 10，即当一个流的有效数据包数量达到 10 时，便进行一次特征提取，以此有效保障了数据集的有效性。

**（三）流量图像的提取**

经资料调研，本项目选用 CNN 模型，通过将流量数据转化为图像的方式，实现恶意流量的多分类。在资料查阅过程中，确定了数据包的预处理方式：把绝对时间转换为相对于流的第一个数据包的相对时间，直接删除 IP、MAC 地址以及 payload，随后将数据包转化为 28×28 的图像格式，进而利用 CNN 模型开展多分类工作。

**（四）前后端的开发**

前端通过vue3+vite+typescript进行快速的开发，后端使用fastapi进行快速开发

## **2.4 作品特色**

### 创意：

1.  **命令行启动**  
    考虑到恶意流量检测平台主要面向部署于 Linux 系统的服务器，本软件借助 argparse 模块，精心打造了命令行启动功能。用户不仅能够通过命令行便捷地启动软件，还可输入 -gui 指令，快速打开由 Vue 框架构建的前端数据可视化界面，实现可视化操作与管理，兼顾不同用户的使用习惯与场景需求。
2.  **实时监测与多元分析**  
    市面上多数恶意流量分类软件在实时检测功能上存在缺失，而本软件通过创新的特征提取与图像转化构思，成功实现了恶意流量的实时监测，能即时察觉潜在威胁。同时，软件支持对过去 7 分钟、7 小时及 7 天内的流量分类数据进行回溯检查，方便用户分析历史流量趋势，排查潜在风险。此外，用户只需输入静态 PCAP 文件路径，软件即可对静态 PCAP 文件展开深度分析，满足多样化的数据分析需求。
3.  **个性化设置界面**  
    本软件提供了丰富多样的设置界面，充分尊重用户的个性化需求。用户可依据自身设备性能，灵活调整数据包检测间隔，在保障检测精度的同时，优化系统运行效率。软件支持对访问 IP 的白名单与黑名单进行设置，有效管控网络访问。同时，用户还能自由指定历史数据文件存储路径以及 PCAP 文件分析路径，让数据管理更加便捷高效。

### 开发实现：

1.  **数据结构与算法优化**  
    在复杂的时序管理任务中，本软件创新性地运用多组双端队列和有限队列。这些数据结构相互协作，能够高效实现大量数据包的快速分割，并巧妙构建过期机制。通过这种方式，极大地节省了内存空间，保障系统在处理海量数据时，依然能够稳定、高效地运行，提升整体性能表现。
2.  **机器学习方法的使用**  
    在机器学习模型搭建方面，本软件投入了大量精力。在 XGBoost 学习过程中，深度挖掘数据特征，精心提取了包括会话流数目、会话和流的特征等在内的共计 153 条关键特征，为模型精准学习提供了丰富的数据基础。而在 CNN 模型构建时，合理设置了两层全连接层与两层卷积层，通过这种架构设计，有效提升模型对图像化流量数据的学习与分类能力，增强恶意流量检测的准确性与可靠性。
3.  **实时抓包与会话管理模块（RealTimePacketAnalysis）设计**

（1）**灵活高效的抓包机制**  
系统基于 Python 网络分析库 Scapy 构建数据包监听引擎，能够对网络中流经的数据进行精准捕获与解析。每个数据包进入处理流程后，会自动提取五元组流信息，并根据本机 IP 判断数据流向（上行或下行），实现对会话的有效划分与跟踪。系统引入白名单与黑名单机制：白名单 IP 的数据包将被忽略处理，减少资源开销；黑名单 IP 将被标记为攻击来源并记录，提升响应效率。

（2）**双模型结构，兼容多种分类方式**  
系统支持两种恶意流量识别模式，用户可按需切换：

- **XGBoost 模式**：提取结构化特征（如长度、持续时间、标志位等）输入传统机器学习模型分类；
- **CNN 模式**：将数据图像化，通过卷积神经网络进行模式识别。  
  系统统一返回分类概率，结合设定阈值判断是否异常并更新攻击记录。

（3）**多时间尺度的数据记录策略**  
引入分钟、小时、天三种时间粒度，每类维护 7 个时间段窗口（如最近 7 分钟的每一分钟数据），采用 deque 数据结构完成高效滑动窗口统计。同时，通过时间戳更新函数保持时间同步，确保统计数据的准确性。

（4）**智能攻击率管理与动态响应机制**  
系统自动计算每个数据包流的攻击概率，并结合攻击标签记录至对应窗口。若概率超过设定阈值，系统将自动将高风险 IP 加入黑名单。上传流量与下载流量分别独立统计，按秒级单位更新，兼顾实时性与资源管理。

（5）**日志持久化与容灾恢复机制**  
系统支持自动持久化日志，将攻击记录、良性记录、分布信息保存至本地 JSON 文件。在下次启动时，自动读取旧日志进行状态恢复，保障异常中断后系统的连续性与数据完整性。

1.  **前端的实现**

（1）**整体架构**  
前端采用 Vue3 框架，结合 Element Plus UI 组件库进行开发。在 App.vue 中通过 el-container 布局构建页面结构，包括顶部栏、侧边栏和主内容区。顶部栏显示平台名称“恶意流量检测平台”，侧边栏提供“实时监控”“历史数据”“日志信息”“系统设置”四个功能模块，用户点击菜单项后通过 selectUI 方法动态切换主内容区组件。

（2）**图表组件实现**  
集成 ECharts 图表库开发多个可视化组件，如 HistoryTrafficGraph.vue 与 MaliciousTrafficClassificationGraph.vue，支持柱状图、折线图切换展示。用户可选择时间单位（分钟/小时/天）进行数据聚合与视图刷新。

（3）**表单与进度条交互**  
在 PcapFileAnalysisUI.vue 页面中，用户输入 PCAP 文件路径后可提交分析请求。通过 el-progress 组件展示处理进度，结合定时轮询后端接口的方式实时获取处理状态，分析完成后将返回结果路径。

（4）**样式设计与优化**  
通过 CSS 重置默认样式，优化顶部栏背景渐变、侧边栏阴影、卡片动画等 UI 细节。使用 scoped 属性限定局部样式，避免全局样式冲突，确保界面美观且功能明确。

（5）**性能优化机制**  
采用异步组件加载（defineAsyncComponent），减少初始加载时间。各组件在生命周期内注册并清理事件监听器，例如在图表组件中使用 onUnmounted 清除定时器与监听器，防止内存泄露。

# 详细设计

## 系统结构设计

### 技术架构

1.  本系统采用本地运行的 B/S（浏览器 / 服务器）平台架构。用户能够通过命令行程序启动本程序，在命令行输入指令时，若加入 “-gui” 参数，系统将自动唤起前端程序，随即呈现实时数据与历史数据的可视化界面，便于用户直观地查看与分析数据
2.  本系统所采用的技术参考了 Tarmain 工具的运用方式。在 Tarmarin 工具里，用户可借助 “-prove” 参数快速执行协议形式化证明，也能通过 “-interact” 参数启动交互界面，以直观的形式展示形式化证明过程。在传统的服务器部署模式中，通常缺少这样的可视化界面，主要依靠命令行参数来完成规则与选项的配置。
3.  由于本项目主要基于 Python 语言进行开发，后端选用 Fastapi 框架搭建路由体系，用于处理各类请求与响应逻辑；前端则采用 vue 框架进行构建，致力于打造用户交互体验良好的界面。

### 功能模块设计

功能模块结构图

Src文件夹中包含了所有的模块，依据功能进行不同的划分：

1.  image 模块：此模块负责对原始数据包执行数据清洗操作，将清洗后的数据转化为 28×28 尺寸的图像格式。经转化后，图像数据可输入至 CNN（卷积神经网络）模型，以实现恶意流量等数据的分类任务 。
2.  feature 模块：该模块从原始数据包中精准提取流和会话层面的特征。这些精心提取的特征，作为关键输入数据，被输送至 xgboost 模型，用于开展机器学习任务，为后续的流量分析和判断奠定基础 。
3.  classifier 模块：承担着对 CNN 模型以及 feature 模块处理流程的训练、模型保存、模型加载工作。同时，此模块还负责预测标签和概率，在整个恶意流量分类体系中，发挥着核心的决策支持作用 。
4.  app 模块：作为后端服务的核心模块，app 模块主要为可视化界面提供数据支撑。在 models 子模块中，定义并保存了前端通过 post 请求发送的数据类型，确保数据交互的规范性与准确性；routers 模块则为前端访问后端资源提供了接口，保障前后端数据通信的顺畅进行 。
5.  data_process 模块：此模块存储了一系列文件处理逻辑。这些逻辑涵盖了对各类数据文件的读取、写入、格式转换等操作，为系统中数据的有效管理和利用提供了必要的支持 。
6.  traffic_sniff 模块：该模块包含两个重要功能组件，分别是用于流量实时监测的 RealtimePacketAnalysis 组件，以及用于静态文件分析的 PcapPacketAnalysis 组件。前者能够实时捕获并分析网络流量，及时发现潜在的恶意流量行为；后者则专注于对静态的 pcap 文件进行深度分析，助力用户了解特定时间段内的网络流量状况 。
7.  config 模块：config 模块内部含有 argus 子模块，主要用于保存系统的设置参数，确保用户配置的参数能够被准确存储和调用；同时，还配备了用于命令行解析的 parse 子模块，能够有效识别和解析用户在命令行输入的指令，为系统提供多样化的启动和配置方式 。

模块调用关系图：

1.  RealtimePacketAnalysis 类和 PcapPacketAnalysis 类为实时或静态数据包处理提供了模型运用功能。这两个类中均包含 CNNClassifier、XgboostClassifier、SessionImage、SessionFeature 这四个类。其中，CNNClassifier 类与 XgboostClassifier 类分别用于基于 CNN 和 Xgboost 的分类；SessionImage 类负责流量图像提取，SessionFeature 类用于流量特征提取。在 CNNClassifier 类里，SimpleCNN 类对 CNN 的卷积层、池化层等结构进行了明确规定。SessionFeature 类借助 FlowFeature 分别对会话和流的特征展开提取。FlowFeature 又包含 TcpFeature 和若干 StatisticalFeature。TcpFeature 主要用于提取 TCP 层的参数特征，例如持续时间、协议以及一些标志位等；StatisticalFeature 则用于提取流的数量特征，涵盖窗口属性、包的长度、字节速率、包速率、段属性、时间间隔属性、空闲和活跃时间以及头部长度等。PcapPacketAnalysis 类会直接依据指定路径保存分析结果；RealtimePacketAnalysis 类通过维护队列的方式保存最近 7 分钟、7 小时或 7 天的数据，并具备白名单豁免与黑名单拦截功能
2.  Config部分规定了一系列配置项，主要有白名单 IP、黑名单 IP、黑名单阈值、数据包检测间隔、pcap 文件分析保存路径、历史记录保存路径以及检测端口。这些配置既能够在可视化界面的前端设置中进行调整，也可以通过命令行来完成设置

### 关键功能/算法设计

1.  RealtimePackageAnalysis算法设计：
2.  数据实时输入处理流程：对于输入的数据包，首先检查其是否处于黑名单或白名单之中。完成检查后，提取流信息中的 flow_id 以及 session_id 。利用 session_id 和自定义的哈希函数 caculate_session_hash 计算出 session_hash，通过该 session_hash 在类属性字典 classifier_dict 中区分不同的会话。classifier 的值依据所选模型，分为 SessionFeature 类型或 SessionImage 类型。为优化内存占用，SessionFeature 类型和 SessionImage 类型均不会保存数据包内容。SessionFeature 类型凭借先前提取的特征以及新输入的数据包，在 O (1) 时间复杂度内计算出新特征；SessionImage 类型在保存的头部信息达到 28×28 图片规格后，输出图片信息并清空原有内容重新开始。这两种类型都设有 update 成员函数，当一个流的数据包数量达到 config 中的 packet_batch_size，或者 28x28 的单通道图像数据已满时，该函数输出特征或图像，并分别将其输入到 Xgboostclassifier 和 cnnclassifier 中。借助 prodcit_proda 函数获取数据包被归类于不同标签的可能性，若可能性最大的标签为 benign，则判定为良性流量，否则为恶性流量，同时记录攻击标签 attack_label 及其对应的攻击率 attack_rate。
3.  **历史数据维护机制**:

·为保存过去 7 分钟、7 小时或 7 天的数据，分别为良性流量和攻击流量设置由 7 个队列构成的队列组。良性流量队列仅保存 flow_id 和抓包时间 time，恶意流量队列则保存 flow_id、attack_rate、attack_label 以及 time 等每个新数据包的分类结果，并提供成员函数 update 用于维护队列。每一组队列中，interval 表示一个队列的时间跨度（单位：秒），分别为 60（对应 7 分钟场景）、60×60（对应 7 小时场景）、60×60×24（对应 7 天场景）。首先获取当前时间，从下标最高的队列开始，从队尾取出元素。若该元素的时间与当前时间的时间差超过 7\*interval，直接丢弃该元素并进入下一步循环。接着通过 caculate_index 计算该元素在当前时间的下标，若下标与当前队列下标相同，则将元素放回队尾并退出循环，处理下一个队列；反之，将元素放入正确下标的队首。

·算法证明：假设存在三个队列 Q1、Q2、Q3，其时间跨度分别为 interval1、interval2、interval3，且 interval1 < interval2 < interval3 ，对应下标为 index1 < index2 < index3。当下标最大的队列 Q3 有元素进入时，必然是在 Q1、Q2 队列已满且时间跨度达到各自上限后才会进入 Q3，所以 Q3 中元素的时间必然晚于 Q1 和 Q2 中的元素，即下标最大的队列时间最大。在队列内部，由于新元素总是从队尾进入，在进行时间校验和下标调整时，若元素时间未超时，只会在本队列内移动，队首元素是队列中最早进入的，队尾元素是最晚进入的，所以每一个队列的时间都是队首最大、队尾最小。

1.  日志保存优化：每 1 秒钟将历史数据保存至 log.json 文件以便日后查看。为减少性能开销，该保存过程由单独线程执行。

2.  PcapPackageAnalysis设计:
3.  **文件输入与进程分配**：输入待处理的文件地址，该地址可以是单个 pcap 文件，若为文件夹，则通过 get_file_list 函数递归查询文件夹中所有的 pcap 文件。为提升处理速度，采用多进程技术，进程数设定为 min (multiprocess.cpu_count () // 2, len (pcap_list))，即取 CPU 核数的一半与 pcap 文件数量两者中的较小值，为每个进程分配一个 pcap 文件。
4.  **文件分析逻辑**：Pcap 文件的分析逻辑与实时分析类似，但无需维护与时间相关的队列，仅需统计不同标签的数量。
5.  **结果统计和保存**：所有进程处理结束后，统计分析标签结构并进行归一化处理，将最终结果保存至对应的指定路径。
6.  **大文件处理机制**：对于体积庞大的 pcap 文件，会先进行基于流的拆分，以防止因文件过大导致程序运行时内存崩溃。具体处理方式如下：
7.  创建一个 pcapReader 对象，对文件进行逐个数据包读取。对于任意输入的数据包，首先计算其 session_hash 作为标识，以此避免将同组 IP 不同方向的数据包划分到不同组。若 session_hash 不在字典 session_dict 中，则创建类 SessionPackage，该类维护一个数据包列表。
8.  创建一个 pcapReader 对象，对文件进行逐个数据包读取。对于任意输入的数据包，首先计算其 session_hash 作为标识，以此避免将同组 IP 不同方向的数据包划分到不同组。若 session_hash 不在字典 session_dict 中，则创建类 SessionPackage，该类维护一个数据包列表。

## 数据结构设计

### 存储数据

**1\. 文件存储**

1.  日志文件 log.json：RealPackageAnalysis 产生的历史数据存储于此文件中。默认情况下，文件路径位于项目文件夹内，文件名为 log.json。用户可通过可视化界面，或者使用命令行参数 “-config_path” 对该文件路径进行更改。该文件主要包含三个核心模块：Attack_queues（攻击队列）、Benign_queues（良性队列）、Attack_distributions（攻击分布）。
2.  Pcap 文件分析结果保存文件 pcap_analysis_result.json：此文件用于保存上次 pcap 文件分析的结果，其文件路径同样可按上述方式更改。文件中数据的保存格式为 {label : distribution}，其中 label 代表分析标签，distribution 表示对应标签的分布情况。
3.  配置文件 config.json：该文件路径固定位于文件夹的第一层目录，不可更改。文件主要包含以下关键信息：black_ip 数组（存储黑名单 IP 地址）、white_ip 数组（存储白名单 IP 地址）、black_threshold（表示黑名单阈值，数据类型为小数）、packet_batch_size（即包处理间隔）、pcap_result_path（记录 pcap 文件路径）、log_path（指定历史数据路径）、port（以整数形式表示端口）。

### 接口（模块接口、系统间接口）

前端与后端的数据交换遵循以下逻辑：

1.  get_attack_distribution：此接口用于返回一个字典，其中字典的值为攻击的标签，键为攻击的分类。通过该接口，前端能够获取不同攻击分类所对应的具体标签信息。
2.  get_attack_type：该接口的作用是获取攻击类型列表。返回的数据中，值是攻击的标签，键是攻击的编码。这使得前端可以清晰地了解各种攻击类型的编码与标签对应关系。
3.  get_black_ip 与 post_black_ip：

· get_black_ip：在该方法中，后端从 config 文件中读取 black_ip 的集合，并将其返回给 前端，使前端能够获取当前系统设置的黑名单 IP 集合。

· post_black_ip：前端向该接口发送 ModifyIP 类型的数据。ModifyIP 数据结构包含一个 op_code，当 op_code 为 True 时，表示要添加 IP；为 False 时，表示要删除 IP，同 时还包含一个表示 IP 地址的字符串。后端接收到数据后，执行相应的添加或删除操作， 并返回一个布尔值，用于告知前端操作是否成功。

1.  get_white_ip 与 post_white_ip：与 get_black_ip 和 post_black_ip 的逻辑类似。

· get_white_ip：后端从 config 文件中读取 white_ip 的集合并返回给前端，让前端获 取 白名单 IP 集合。

· post_white_ip：前端发送 ModifyIP 类型数据，后端根据 op_code 执行添加或删除 IP 操 作，并返回操作结果的布尔值。

1.  black_threshold：

· get 方法：后端返回一个保留两位小数的 float 类型数据，表示 IP 进入黑名单的阈值， 前端可据此获取当前的黑名单阈值设定。

· post 方法：前端发送 BlackThreshold 数据，其中包含一个 threshold 字段，表示要设置 的黑名单阈值。后端接收后更新阈值，并返回更新操作的结果。

1.  classification：

· get 方法：后端返回历史数据给前端。

· post 方法：前端发送 HistoryRequest 数据，其中 dtype 字段可以取值为 'min'（分钟）、 'hour'（小时）、'day'（天），用于指定获取不同时间粒度的分类历史数据。后端根据前 端请求返回相应的历史数据。

1.  packet_batch_size：

· get 方法：后端返回整数 config.packet_batch_size，前端可通过此接口获取当前设置的 包处理间隔。

· post 方法：前端发送 PacketBatchSize 模型数据，其中的 delay 字段值将被赋值给 config.packet_batch_size。后端完成赋值操作后，返回更改结果。

1.  pcap_process：前端调用此接口，用于启动静态的 pcap 文件分析任务。
2.  port：

· get 方法：后端返回一个整数，表示当前的端口号，前端可获取系统当前使用的端口信 息。

post 方法：前端发送要修改的端口值，后端更新 config.port 并返回修改结果。

1.  pcap_result_path：

· get 方法：后端返回一个字符串，该字符串表示 pcap 文件处理后的结果保存路径，前 端可获取此路径信息。

· post 方法：前端发送 ModifyPath 数据，其中含有 path 字段表示要修改的路径。后端 更新路径设置后，返回修改结果的布尔值。

1.  process：如果当前没有进行静态的 pcap 文件处理，后端返回结果 100；若正在进行处理，则返回当前的处理进度，前端可据此了解 pcap 文件分析任务的执行状态。
2.  log_path：

· get 方法：后端返回一个字符串，表示 log 文件的路径，前端可获取日志文件的存储路 径信息。

· post 方法：前端发送 ModifyPath 数据，其中含有 path 字段表示要修改的路径。后端 更新日志文件路径设置后，返回修改结果的布尔值。

### 关键数据结构

关键信息:

config 存储结构：

该结构是从 JSON 文件加载而来，用于存储系统的一些关键配置信息。

black_ip：以集合（set）的形式存储黑名单 IP 地址，从 JSON 数据中 "black_ip" 键对应的值（默认为空列表 \[\]）转换而来。

white_ip：以集合（set）的形式存储白名单 IP 地址，从 JSON 数据中 "white_ip" 键对应的值（默认为空列表 \[\]）转换而来。

black_threshold：表示黑名单阈值，从 JSON 数据中 "black_threshold" 键对应的值获取，默认值为 0.0。

pcap_result_path：表示 pcap 文件的结果保存路径，从 JSON 数据中 "pcap_result_path" 键对应的值获取，若没有则使用默认路径 default_pcap_result_path。

log_path：表示日志文件的保存路径，从 JSON 数据中 "log_path" 键对应的值获取，若没有则使用默认路径 default_log_path。

port：以集合（set）的形式存储端口信息，从 JSON 数据中 "port" 键对应的值（默认为空列表 \[\]）转换而来。

packet_batch_size：表示数据包批次大小，从 JSON 数据中 "packet_batch_size" 键对应的值获取，默认值为 10。

历史日志存储结构：

这是一个包含攻击和正常流量相关统计信息的 JSON 格式结构。

attack_queues：是一个二维数组，每个子数组（共 3 个）代表一个时间窗口或某种分类下的攻击队列，每个子数组内部又包含多个空数组，可能用于存储不同类型或阶段的攻击相关数据。

benign_queues：与 attack_queues 类似，也是二维数组，代表正常流量的队列信息，每个子数组内部的空数组可能用于存储正常流量的相关数据。

attack_distributions：是一个二维数组，每个子数组（共 3 个）包含 12 个数值，这些数值可能表示不同类型或阶段的攻击分布情况，例如不同攻击类型的计数或占比等。

pcap 分析结构存储结构：

这是一个 JSON 格式的结构，用于存储 pcap 文件分析的结果。

结构中包含键值对，其中键为 "attack_label"，值为相应攻击标签在分析结果中的占比情况。每个键值对表示一种攻击标签及其对应的占比信息。

## 系统界面设计

### 界面设计风格

主页面采用简洁直观的布局，以蓝色调为主营造科技感。顶部是蓝色横幅，显示 “恶意流量检测平台”。左侧为深色导航栏，包含 “实时监控”“历史数据”“日志信息”“系统设置” 等流量监测选项，图标简洁明了，分别对应各功能模块，便于用户快速识别和点击。

主体区域根据不同功能页面展示相应内容。整体图像风格为扁平化设计，去除多余装饰，元素清晰、简洁，数据展示区域使用图表直观呈现信息，提升用户获取数据的效率。

### 主要功能页面

【介绍主要功能页面，并简要介绍这些页面的设计特色、操作方法。】

- **实时监控页面**：
  - **设计特色**：以直观的图表展示实时流量信息。“实时流量监控” 区域用环形图展示正常流量和恶意流量占比，同时标注 “攻击率”，并显示上下行流量速率。“恶意流量分类” 区域以饼图呈现不同攻击类型占比，色彩丰富且区分度高。下方 “流量分析” 部分以列表形式展示相关 IP 地址及攻击率，绿色标识凸显攻击率信息。
  - **操作方法**：用户无需复杂操作，进入页面即可实时查看流量及恶意流量分类情况。可通过观察图表和列表数据，快速掌握网络实时安全状态。
- **历史数据页面**：
  - **设计特色**：“历史流量监控” 区域采用柱状图展示不同时间单位（可选择分钟、小时、天）内正常流量和恶意流量情况，用户可按需切换时间单位查看流量变化趋势。“恶意流量分类” 饼图与实时监控页面类似，展示历史恶意流量攻击类型占比。“历史流量分析” 列表同样展示相关 IP 及攻击率。
  - **操作方法**：在时间单位选择框点击切换时间维度，柱状图会实时更新展示对应时间范围的流量数据；通过观察列表和饼图，可分析历史恶意流量情况。
- **PCAP 文件分析页面**：设计简洁，仅有输入框和提交按钮，用户输入 PCAP 文件夹路径后点击 “提交”，即可对指定 PCAP 文件进行恶意流量分析。
- **系统设置页面**：分为 “IP 管理” 和 “系统设置” 板块。“IP 管理” 可切换管理白名单和黑名单。“系统设置” 以表单形式呈现 “监听端口”“特征提取间隔” 等设置项，每个设置项旁有 “修改” 按钮，黑名单阈值可通过滑块调整，方便用户按需配置系统参数。

### Web网站页面结构设计

图2 Web网站页面结构图

# 系统安装及使用说明

本系统是一个恶意流量检测平台，提供实时监控、历史数据查询、日志信息分析以及系统设置等功能。系统支持通过命令行进行参数配置，也提供了图形化用户界面（GUI）方便用户操作。

系统安装

1.  环境准备

确保你已经安装了以下软件：

\- Node.js（建议版本 14 及以上）

\- Python（建议版本 3.7 及以上）

前端项目安装

1.  克隆项目代码：

（bash）

git clone [git@github.com:050125hhh/fronted_platforn.git](mailto:git@github.com:050125hhh/fronted_platforn.git)

cd fronted_platform

1.  安装依赖：

（bash）

npm install

1.  启动开发服务器：

（bash）

npm run dev

启动后，你可以在浏览器中访问 http://localhost:3000查看系统界面。

后端项目安装

1.  安装 Python 依赖：

（bash）

pip install -r requirements.txt

1.  启动后端服务：

（bash）

python main.py

确保后端服务监听在 http://localhost:8000端口，前端代码中默认使用该地址进行数据请求。

系统使用

命令行使用

你可以使用命令行工具对系统进行配置和操作，以下是一些常用命令：

\- 显示当前版本号：

（bash）

python parse.py -version

\- 显示帮助信息：

（bash）

python parse.py -help

\- 打开 GUI 界面：

（bash）

python parse.py -gui

\- 清空配置文件：

（bash）

python parse.py -clear_config

\- 修改日志文件路径：

（bash）

python parse.py -change_log /path/to/log/file

\- 添加白名单：

（bash）

python parse.py -add_white 192.168.1.1

\- 添加黑名单：

（bash）

python parse.py -add_black 192.168.1.2

\- 启动监控程序：

（bash）

python parse.py -start_monitor

GUI 使用

打开浏览器，访问 \`http://localhost:3000\` 进入系统界面

界面包含以下主要功能模块：

1.  实时监控：实时展示网络流量信息，可及时发现异常流量。
2.  历史数据：查询和分析历史流量数据，帮助用户了解网络流量的变化趋势。
3.  日志信息：对 PCAP 文件进行分析，并显示分析结果。
4.  系统设置：

\- IP 管理：可以管理白名单和黑名单，添加或删除 IP 地址。

\- 系统设置：可以修改监听端口、特征提取间隔、日志存储路径、PCAP 分析保存地址以及黑名单阈值等系统参数。

# 总结

本恶意流量检测平台以应对复杂网络安全威胁为核心目标，在创意与开发实现层面展现出显著特色与成果。

在创意方面，平台突破传统恶意流量检测软件的局限，融合命令行启动与可视化操作，兼顾服务器部署场景与用户交互体验；通过实时监测、多时间尺度历史数据分析及静态 PCAP 文件处理，构建了全方位的流量安全监测体系；个性化设置界面允许用户灵活调整检测参数、管理 IP 名单与数据存储路径，极大提升了系统的适用性与易用性。

开发实现过程中，团队综合运用多种前沿技术与创新设计。数据处理层面，通过优化数据结构（如双端队列与有限队列组合）和多线程技术，高效解决了大文件分割与海量数据包处理的性能瓶颈；机器学习模块中，XGBoost 与 CNN 模型的深度应用，结合精细化的特征工程与图像化数据转换，显著提升了恶意流量识别的准确性；实时抓包与会话管理模块的设计，集成动态黑名单机制、双模型分类与多时间尺度统计，保障了系统对攻击行为的快速响应与精准记录；前端基于 Vue3 与 ECharts 的可视化开发，实现了数据的直观呈现与流畅交互。

然而，项目仍存在优化空间。在算法性能上，可探索更轻量化的深度学习模型或集成迁移学习技术，降低计算资源消耗，提升实时检测效率；面对不断演变的网络攻击手段，需持续更新数据集与模型训练策略，增强对新型攻击的识别能力；系统架构方面，可考虑引入分布式设计，提高平台的扩展性与容错性，以适应大规模网络环境的监测需求。未来，团队将围绕这些方向持续改进，致力于打造更智能、高效、可靠的恶意流量检测解决方案。

# 附录

## 名词定义

|           |                                                  |
| --------- | ------------------------------------------------ |
| 名词/缩写 | 说明                                             |
| 会话      | 指两个IP之间的所有通信                           |
| 流        | 基于（源IP，目的IP，源端口，目的端口，协议）分割 |
|           |                                                  |
|           |                                                  |

## 参考资料

\[1\]翟明芳,张兴明,赵博.基于深度学习的加密恶意流量检测研究\[J\].网络与信息安全学报,2020,6(3):66-77

\[2\] 祖伟，张顺良，赵洪策. 基于深度学习的恶意加密流量检测及对抗技术综述\[J\]. 信息安全学报，2024，9(4)：357-378.

## 源代码清单

后端：

src

|---- app

|---- models

| |---- black_threshold.py

| |---- history.py

| |---- ip.py

| |---- model.py

| |---- packet_batch_size.py

| |---- path.py

| |---- port.py

|---- routers

| |---- attack_distribution.py

| |---- black_ip.py

| |---- black_threshold.py

| |---- delay.py

| |---- history_attack_distribution.py

| |---- history.py

| |---- logpath.py

| |---- maliciousrate.py

| |---- model.py

| |---- nrate.py

| |---- pcap_process.py

| |---- port.py

| |---- process.py

| |---- respath.py

| |---- white_ip.py

|---- classifiers

|---- config

|---- argus.py

|---- parse.py

|---- data_process

|---- csv

| |---- collect_protocol.py

| |---- drop_columns.py

| |---- extract_label.py

|---- io.py

|---- modify_label.py

|---- pcap

|---- extract_feature.py

|---- extract_image.py

|---- io.py

|---- spite_pcap.py

|---- png

|---- io.py

|---- utils

|---- col.py

|---- get_file_list.py

|---- label.py

|---- multi_process.py

|---- preprocess.py

|---- print_info.py

|---- test_model.py

|---- features

|---- flow

|---- feature.py

|---- key.py

|---- packets.py

|---- session

|---- feature.py

|---- key.py

|---- packets.py

|---- statistical_feature.py

|---- tcp_feature.py

|---- image

|---- session_image.py

|----traffic_sniff

|---- pcap_packet_analysis.py

|---- realtime_packet_analysis.py

|----main.py

前端：

src

|---- components

| |---- BlackIP.vue

| |---- HistoryTrafficGraph.vue

| |---- MacliousTrafficClassificationGraphByTime.vue

| |---- RealTimeTrafficGraph.vue

| |---- WhiteIP.vue

|---- router

| |---- index.ts

|---- views

| |---- HistoryTrafficAnalysisUI.vue

| |---- PcapFileAnalysisUI.vue

| |---- RealTimeTrafficAnalysisUI.vue

| |---- SettingUI.vue

|---- App.vue

|---- main.ts

|---- style.css

|---- vite-env.d.ts
